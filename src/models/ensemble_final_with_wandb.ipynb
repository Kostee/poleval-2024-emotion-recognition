{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Weights & Biases package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.17.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (5.9.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (2.9.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.5)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\panko\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\panko\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & log into Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\panko\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkosternaj\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\panko\\OneDrive\\Pulpit\\Studia\\IL\\poleval_emotion\\src\\models\\wandb\\run-20240712_192254-s8s2eezn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kosternaj/poleval-2024-emotion-recognition/runs/s8s2eezn' target=\"_blank\">snowy-river-1</a></strong> to <a href='https://wandb.ai/kosternaj/poleval-2024-emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kosternaj/poleval-2024-emotion-recognition' target=\"_blank\">https://wandb.ai/kosternaj/poleval-2024-emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kosternaj/poleval-2024-emotion-recognition/runs/s8s2eezn' target=\"_blank\">https://wandb.ai/kosternaj/poleval-2024-emotion-recognition/runs/s8s2eezn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kosternaj/poleval-2024-emotion-recognition/runs/s8s2eezn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x29b8fb6a530>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"poleval-2024-emotion-recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.learning_rate = 0.001\n",
    "config.epochs = 200\n",
    "config.batch_size = 10\n",
    "config.max_iter = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/poleval_emotion/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/train/concated_for_ensemble_final.csv')\n",
    "y = pd.read_csv('data/train/expected.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1613)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definitions (CNN & Naive Bayes: later))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'xgboost': XGBClassifier(),\n",
    "    'mlp': MLPClassifier(max_iter=2000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# For testing\n",
    "param_grids = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10],\n",
    "        'bootstrap': [True]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [0.01],\n",
    "        'max_depth': [3, 5],\n",
    "        'gamma': [0]\n",
    "    },\n",
    "    'mlp': {\n",
    "    'hidden_layer_sizes': [(100,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001]\n",
    "    }\n",
    "}\n",
    "'''\n",
    "param_grids = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'gamma': [0, 0.1]\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50), (100, 50), (50, 50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(11, activation='sigmoid'))  # Assuming 11 classes\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models/ensemble_final/'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model, param_grid):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        return grid_search.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models with standard multi-label classification approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: random_forest\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Accuracy for random_forest: 0.9191073919107392\n",
      "\n",
      "Training model: xgboost\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Accuracy for xgboost: 0.9149232914923291\n",
      "\n",
      "Training model: mlp\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Accuracy for mlp: 0.9135285913528591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "for model_name in ['random_forest', 'xgboost', 'mlp']:\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    best_estimator = tune_model(models[model_name], param_grids[model_name])\n",
    "    multi_target_model = MultiOutputClassifier(best_estimator)\n",
    "    multi_target_model.fit(X_train, y_train)\n",
    "    y_pred = multi_target_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics into wandb\n",
    "    wandb.log({f\"accuracy_{model_name}\": accuracy})\n",
    "    \n",
    "    print(f\"Accuracy for {model_name}: {accuracy}\\n\")\n",
    "    trained_models[model_name] = multi_target_model\n",
    "    dump(multi_target_model, os.path.join(model_dir, f'{model_name}.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: cnn\n",
      "Epoch 1/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1430 - loss: 0.1296\n",
      "Epoch 2/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1972 - loss: 0.0493\n",
      "Epoch 3/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2437 - loss: 0.0455\n",
      "Epoch 4/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2216 - loss: 0.0489\n",
      "Epoch 5/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2582 - loss: 0.0419\n",
      "Epoch 6/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3118 - loss: 0.0449\n",
      "Epoch 7/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3196 - loss: 0.0402\n",
      "Epoch 8/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2979 - loss: 0.0413\n",
      "Epoch 9/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3063 - loss: 0.0356\n",
      "Epoch 10/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3320 - loss: 0.0368\n",
      "Epoch 11/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3096 - loss: 0.0373\n",
      "Epoch 12/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3861 - loss: 0.0359\n",
      "Epoch 13/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3009 - loss: 0.0352\n",
      "Epoch 14/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4008 - loss: 0.0356\n",
      "Epoch 15/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3387 - loss: 0.0346\n",
      "Epoch 16/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.0352\n",
      "Epoch 17/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3240 - loss: 0.0325\n",
      "Epoch 18/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4146 - loss: 0.0313\n",
      "Epoch 19/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3651 - loss: 0.0317\n",
      "Epoch 20/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3814 - loss: 0.0344\n",
      "Epoch 21/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4094 - loss: 0.0341\n",
      "Epoch 22/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3895 - loss: 0.0332\n",
      "Epoch 23/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4008 - loss: 0.0326\n",
      "Epoch 24/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3861 - loss: 0.0321\n",
      "Epoch 25/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3545 - loss: 0.0311\n",
      "Epoch 26/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3959 - loss: 0.0294\n",
      "Epoch 27/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4290 - loss: 0.0324\n",
      "Epoch 28/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3896 - loss: 0.0309\n",
      "Epoch 29/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3385 - loss: 0.0296\n",
      "Epoch 30/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3796 - loss: 0.0304\n",
      "Epoch 31/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4211 - loss: 0.0294\n",
      "Epoch 32/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4425 - loss: 0.0297\n",
      "Epoch 33/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4107 - loss: 0.0317\n",
      "Epoch 34/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4507 - loss: 0.0281\n",
      "Epoch 35/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3627 - loss: 0.0277\n",
      "Epoch 36/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4070 - loss: 0.0293\n",
      "Epoch 37/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3728 - loss: 0.0296\n",
      "Epoch 38/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3982 - loss: 0.0274\n",
      "Epoch 39/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 0.0296\n",
      "Epoch 40/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4368 - loss: 0.0288\n",
      "Epoch 41/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3608 - loss: 0.0271\n",
      "Epoch 42/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4541 - loss: 0.0293\n",
      "Epoch 43/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 0.0289\n",
      "Epoch 44/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3813 - loss: 0.0258\n",
      "Epoch 45/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4033 - loss: 0.0283\n",
      "Epoch 46/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4743 - loss: 0.0269\n",
      "Epoch 47/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3899 - loss: 0.0281\n",
      "Epoch 48/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3651 - loss: 0.0254\n",
      "Epoch 49/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3482 - loss: 0.0258\n",
      "Epoch 50/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3616 - loss: 0.0263\n",
      "Epoch 51/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4418 - loss: 0.0243\n",
      "Epoch 52/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4043 - loss: 0.0271\n",
      "Epoch 53/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3944 - loss: 0.0270\n",
      "Epoch 54/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4136 - loss: 0.0279\n",
      "Epoch 55/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4280 - loss: 0.0247\n",
      "Epoch 56/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3879 - loss: 0.0263\n",
      "Epoch 57/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4255 - loss: 0.0263\n",
      "Epoch 58/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4501 - loss: 0.0260\n",
      "Epoch 59/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4716 - loss: 0.0243\n",
      "Epoch 60/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4112 - loss: 0.0240\n",
      "Epoch 61/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4494 - loss: 0.0244\n",
      "Epoch 62/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4145 - loss: 0.0240\n",
      "Epoch 63/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4503 - loss: 0.0230\n",
      "Epoch 64/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4619 - loss: 0.0243\n",
      "Epoch 65/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4340 - loss: 0.0251\n",
      "Epoch 66/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4162 - loss: 0.0231\n",
      "Epoch 67/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4361 - loss: 0.0208\n",
      "Epoch 68/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4674 - loss: 0.0248\n",
      "Epoch 69/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4989 - loss: 0.0261\n",
      "Epoch 70/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4714 - loss: 0.0254\n",
      "Epoch 71/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: 0.0236\n",
      "Epoch 72/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4708 - loss: 0.0219\n",
      "Epoch 73/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4239 - loss: 0.0218\n",
      "Epoch 74/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4536 - loss: 0.0235\n",
      "Epoch 75/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4737 - loss: 0.0247\n",
      "Epoch 76/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4851 - loss: 0.0235\n",
      "Epoch 77/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4806 - loss: 0.0250\n",
      "Epoch 78/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4290 - loss: 0.0251\n",
      "Epoch 79/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4914 - loss: 0.0268\n",
      "Epoch 80/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4562 - loss: 0.0219\n",
      "Epoch 81/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4857 - loss: 0.0236\n",
      "Epoch 82/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4746 - loss: 0.0222\n",
      "Epoch 83/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4849 - loss: 0.0248\n",
      "Epoch 84/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4635 - loss: 0.0206\n",
      "Epoch 85/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4729 - loss: 0.0211\n",
      "Epoch 86/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4658 - loss: 0.0213\n",
      "Epoch 87/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4794 - loss: 0.0251\n",
      "Epoch 88/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4661 - loss: 0.0250\n",
      "Epoch 89/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4547 - loss: 0.0235\n",
      "Epoch 90/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4832 - loss: 0.0243\n",
      "Epoch 91/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4920 - loss: 0.0222\n",
      "Epoch 92/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4883 - loss: 0.0232\n",
      "Epoch 93/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4859 - loss: 0.0206\n",
      "Epoch 94/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4745 - loss: 0.0215\n",
      "Epoch 95/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4356 - loss: 0.0224\n",
      "Epoch 96/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4637 - loss: 0.0247\n",
      "Epoch 97/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4712 - loss: 0.0219\n",
      "Epoch 98/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4567 - loss: 0.0222\n",
      "Epoch 99/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4855 - loss: 0.0215\n",
      "Epoch 100/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4820 - loss: 0.0224\n",
      "Epoch 101/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4928 - loss: 0.0232\n",
      "Epoch 102/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4419 - loss: 0.0242\n",
      "Epoch 103/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4959 - loss: 0.0251\n",
      "Epoch 104/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 0.0222\n",
      "Epoch 105/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4909 - loss: 0.0215\n",
      "Epoch 106/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4883 - loss: 0.0213\n",
      "Epoch 107/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4656 - loss: 0.0197\n",
      "Epoch 108/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4807 - loss: 0.0201\n",
      "Epoch 109/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.0234\n",
      "Epoch 110/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5008 - loss: 0.0209\n",
      "Epoch 111/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4965 - loss: 0.0228\n",
      "Epoch 112/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4800 - loss: 0.0219\n",
      "Epoch 113/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4847 - loss: 0.0209\n",
      "Epoch 114/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4535 - loss: 0.0233\n",
      "Epoch 115/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4255 - loss: 0.0210\n",
      "Epoch 116/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4228 - loss: 0.0211\n",
      "Epoch 117/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4694 - loss: 0.0197\n",
      "Epoch 118/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4709 - loss: 0.0215\n",
      "Epoch 119/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4595 - loss: 0.0208\n",
      "Epoch 120/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4639 - loss: 0.0214\n",
      "Epoch 121/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4743 - loss: 0.0216\n",
      "Epoch 122/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4729 - loss: 0.0232\n",
      "Epoch 123/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4599 - loss: 0.0212\n",
      "Epoch 124/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 0.0170\n",
      "Epoch 125/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4780 - loss: 0.0192\n",
      "Epoch 126/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4938 - loss: 0.0200\n",
      "Epoch 127/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4840 - loss: 0.0208\n",
      "Epoch 128/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4623 - loss: 0.0216\n",
      "Epoch 129/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5047 - loss: 0.0203\n",
      "Epoch 130/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4600 - loss: 0.0221\n",
      "Epoch 131/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4952 - loss: 0.0187\n",
      "Epoch 132/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5002 - loss: 0.0208\n",
      "Epoch 133/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4624 - loss: 0.0187\n",
      "Epoch 134/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4882 - loss: 0.0211\n",
      "Epoch 135/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4624 - loss: 0.0203\n",
      "Epoch 136/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4785 - loss: 0.0211\n",
      "Epoch 137/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5176 - loss: 0.0190\n",
      "Epoch 138/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4938 - loss: 0.0218\n",
      "Epoch 139/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5061 - loss: 0.0218\n",
      "Epoch 140/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 0.0211\n",
      "Epoch 141/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4825 - loss: 0.0198\n",
      "Epoch 142/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4526 - loss: 0.0196\n",
      "Epoch 143/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5071 - loss: 0.0192\n",
      "Epoch 144/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4818 - loss: 0.0210\n",
      "Epoch 145/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5130 - loss: 0.0181\n",
      "Epoch 146/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4623 - loss: 0.0176\n",
      "Epoch 147/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5174 - loss: 0.0172\n",
      "Epoch 148/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5197 - loss: 0.0183\n",
      "Epoch 149/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4735 - loss: 0.0192\n",
      "Epoch 150/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4439 - loss: 0.0201\n",
      "Epoch 151/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5172 - loss: 0.0177\n",
      "Epoch 152/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4604 - loss: 0.0175\n",
      "Epoch 153/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4706 - loss: 0.0195\n",
      "Epoch 154/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5070 - loss: 0.0179\n",
      "Epoch 155/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4900 - loss: 0.0160\n",
      "Epoch 156/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5076 - loss: 0.0198\n",
      "Epoch 157/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4922 - loss: 0.0197\n",
      "Epoch 158/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5292 - loss: 0.0185\n",
      "Epoch 159/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4287 - loss: 0.0199\n",
      "Epoch 160/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4880 - loss: 0.0210\n",
      "Epoch 161/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4879 - loss: 0.0198\n",
      "Epoch 162/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4342 - loss: 0.0176\n",
      "Epoch 163/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: 0.0195\n",
      "Epoch 164/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4262 - loss: 0.0194\n",
      "Epoch 165/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4526 - loss: 0.0186\n",
      "Epoch 166/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4814 - loss: 0.0204\n",
      "Epoch 167/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5263 - loss: 0.0185\n",
      "Epoch 168/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4479 - loss: 0.0188\n",
      "Epoch 169/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5061 - loss: 0.0196\n",
      "Epoch 170/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4622 - loss: 0.0205\n",
      "Epoch 171/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4693 - loss: 0.0191\n",
      "Epoch 172/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4782 - loss: 0.0199\n",
      "Epoch 173/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4912 - loss: 0.0190\n",
      "Epoch 174/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 0.0182\n",
      "Epoch 175/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5110 - loss: 0.0161\n",
      "Epoch 176/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4727 - loss: 0.0191\n",
      "Epoch 177/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4822 - loss: 0.0200\n",
      "Epoch 178/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4871 - loss: 0.0199\n",
      "Epoch 179/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 0.0178\n",
      "Epoch 180/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4803 - loss: 0.0186\n",
      "Epoch 181/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4660 - loss: 0.0171\n",
      "Epoch 182/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4561 - loss: 0.0198\n",
      "Epoch 183/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4645 - loss: 0.0189\n",
      "Epoch 184/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4359 - loss: 0.0173\n",
      "Epoch 185/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4939 - loss: 0.0180\n",
      "Epoch 186/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4433 - loss: 0.0197\n",
      "Epoch 187/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4867 - loss: 0.0199\n",
      "Epoch 188/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 0.0191\n",
      "Epoch 189/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4982 - loss: 0.0197\n",
      "Epoch 190/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4777 - loss: 0.0181\n",
      "Epoch 191/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4710 - loss: 0.0204\n",
      "Epoch 192/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4357 - loss: 0.0187\n",
      "Epoch 193/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5247 - loss: 0.0175\n",
      "Epoch 194/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4923 - loss: 0.0174\n",
      "Epoch 195/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4869 - loss: 0.0187\n",
      "Epoch 196/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5162 - loss: 0.0190\n",
      "Epoch 197/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4687 - loss: 0.0181\n",
      "Epoch 198/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5094 - loss: 0.0192\n",
      "Epoch 199/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4983 - loss: 0.0167\n",
      "Epoch 200/200\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4437 - loss: 0.0191\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for cnn: 0.895397489539749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model: cnn\")\n",
    "cnn_model = create_cnn_model((X_train.shape[1], 1))\n",
    "cnn_model.fit(X_train.values[..., np.newaxis], y_train.values, \n",
    "              epochs=config.epochs, batch_size=config.batch_size, \n",
    "              verbose=1)\n",
    "cnn_y_pred = cnn_model.predict(X_test.values[..., np.newaxis])\n",
    "cnn_y_pred = (cnn_y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "cnn_accuracy = accuracy_score(y_test, cnn_y_pred)\n",
    "\n",
    "# Log metrics into wandb\n",
    "wandb.log({\"accuracy_cnn\": cnn_accuracy})\n",
    "print(f\"Accuracy for cnn: {cnn_accuracy}\\n\")\n",
    "cnn_model.save(os.path.join(model_dir, 'cnn.h5'))\n",
    "trained_models['cnn'] = cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Naive Bayes models independently for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: naive_bayes\n",
      "Accuracy for label Joy with Naive Bayes: 0.9609483960948396\n",
      "Accuracy for label Trust with Naive Bayes: 0.7580195258019525\n",
      "Accuracy for label Anticipation with Naive Bayes: 0.99302649930265\n",
      "Accuracy for label Surprise with Naive Bayes: 0.7580195258019525\n",
      "Accuracy for label Fear with Naive Bayes: 0.9693165969316597\n",
      "Accuracy for label Sadness with Naive Bayes: 0.9567642956764296\n",
      "Accuracy for label Disgust with Naive Bayes: 0.8521617852161785\n",
      "Accuracy for label Anger with Naive Bayes: 0.8486750348675035\n",
      "Accuracy for label Positive with Naive Bayes: 0.9665271966527197\n",
      "Accuracy for label Negative with Naive Bayes: 0.9288702928870293\n",
      "Accuracy for label Neutral with Naive Bayes: 0.9532775453277545\n",
      "\n",
      "Mean Accuracy for Naive Bayes: 0.9041460631418791\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model: naive_bayes\")\n",
    "nb_models = []\n",
    "nb_accuracies = []\n",
    "for i in range(y_train.shape[1]):\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train.iloc[:, i])\n",
    "    nb_models.append(nb_model)\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred)\n",
    "    nb_accuracies.append(accuracy)\n",
    "    \n",
    "    # Log metrics into wandb\n",
    "    wandb.log({f\"accuracy_naive_bayes_{y_train.columns[i]}\": accuracy})\n",
    "    print(f\"Accuracy for label {y_train.columns[i]} with Naive Bayes: {accuracy}\")\n",
    "\n",
    "mean_nb_accuracy = np.mean(nb_accuracies)\n",
    "\n",
    "# # Log mean accuracy into wandb\n",
    "wandb.log({\"mean_accuracy_naive_bayes\": mean_nb_accuracy})\n",
    "print(f\"\\nMean Accuracy for Naive Bayes: {mean_nb_accuracy}\")\n",
    "dump(nb_models, os.path.join(model_dir, 'naive_bayes.joblib'))\n",
    "trained_models['naive_bayes'] = nb_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super ensemble model using majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_ensemble_predict(models, X):\n",
    "    predictions = []\n",
    "    for model_name, model in models.items():\n",
    "        if model_name == 'cnn':\n",
    "            pred = model.predict(X.values[..., np.newaxis])\n",
    "            pred = (pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "        elif model_name == 'naive_bayes':\n",
    "            pred = np.column_stack([nb_model.predict(X) for nb_model in model])\n",
    "        else:\n",
    "            pred = model.predict(X)\n",
    "        predictions.append(pred)\n",
    "    predictions = np.array(predictions)\n",
    "    majority_vote = mode(predictions, axis=0).mode[0]\n",
    "    return majority_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the super ensemble model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ensemble_final/super_ensemble_model.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(super_ensemble_predict, os.path.join(model_dir, 'super_ensemble_model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testA = pd.read_csv('data/testA/concated_for_ensemble_final.csv')\n",
    "X_testB = pd.read_csv('data/testB/concated_for_ensemble_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and save the results for testA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panko\\AppData\\Local\\Temp\\ipykernel_26572\\814255698.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority_vote = mode(predictions, axis=0).mode[0]\n"
     ]
    }
   ],
   "source": [
    "predictions_testA = super_ensemble_predict(trained_models, X_testA)\n",
    "predictions_testA_df = pd.DataFrame(predictions_testA, columns=y.columns)\n",
    "os.makedirs('predictions/testA/ensemble_final/', exist_ok=True)\n",
    "predictions_testA_df.to_csv('predictions/testA/ensemble_final/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.save('predictions/testA/ensemble_final/predictions_wandb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and save the results for testB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panko\\AppData\\Local\\Temp\\ipykernel_26572\\814255698.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority_vote = mode(predictions, axis=0).mode[0]\n"
     ]
    }
   ],
   "source": [
    "predictions_testB = super_ensemble_predict(trained_models, X_testB)\n",
    "predictions_testB_df = pd.DataFrame(predictions_testB, columns=y.columns)\n",
    "os.makedirs('predictions/testB/ensemble_final/', exist_ok=True)\n",
    "predictions_testB_df.to_csv('predictions/testB/ensemble_final/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.save('predictions/testB/ensemble_final/predictions_wandb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training, saving, and predictions complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Model training, saving, and predictions complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
